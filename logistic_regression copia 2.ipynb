{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GeNNus Simone & Paolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = \"xs\"\n",
    "DATASET_TYPE = \"waveform\"\n",
    "\n",
    "DATASET_FOLDER = f\"./data/{DATASET_TYPE}\"\n",
    "\n",
    "DATASET_NUM_SAMPLES_PER_SECOND = 8000\n",
    "DATASET_NUM_CHANNELS = 1\n",
    "\n",
    "DATASET_NAME = f\"fma_{DATASET_SIZE}_resampled_{DATASET_NUM_SAMPLES_PER_SECOND}_rechanneled_{DATASET_NUM_CHANNELS}\"\n",
    "\n",
    "dataset_path = f\"{DATASET_FOLDER}/{DATASET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path_list = []\n",
    "\n",
    "for path, subdirs, files in os.walk(dataset_path):\n",
    "    for name in files:\n",
    "        file_audio_path = os.path.join(path, name)\n",
    "        #print(file_audio_path)\n",
    "\n",
    "        if name != '.DS_Store':\n",
    "            audio_path_list.append(file_audio_path)\n",
    "\n",
    "audio_path_list = sorted(audio_path_list , reverse= True)\n",
    "# lista di tutti i path     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_tensors = []\n",
    "labels = []\n",
    "\n",
    "for p in audio_path_list:\n",
    "    single_tensors.append(torch.load(p))\n",
    "    #print(p)\n",
    "    labels.append(p.split(\"/\")[-2])\n",
    "\n",
    "single_tensors # --> waveforms\n",
    "labels # --> etichette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_single_tensors = torch.cat(single_tensors).numpy()\n",
    "#stacked_single_tensors.shape\n",
    "stacked_single_tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(stacked_single_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(0, \"Label\", labels, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>237990</th>\n",
       "      <th>237991</th>\n",
       "      <th>237992</th>\n",
       "      <th>237993</th>\n",
       "      <th>237994</th>\n",
       "      <th>237995</th>\n",
       "      <th>237996</th>\n",
       "      <th>237997</th>\n",
       "      <th>237998</th>\n",
       "      <th>237999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rock</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.004120</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>-0.003272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248962</td>\n",
       "      <td>0.085129</td>\n",
       "      <td>-0.020552</td>\n",
       "      <td>-0.232211</td>\n",
       "      <td>-0.366932</td>\n",
       "      <td>-0.380118</td>\n",
       "      <td>-0.329189</td>\n",
       "      <td>-0.377189</td>\n",
       "      <td>-0.429503</td>\n",
       "      <td>-0.469498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rock</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>-0.000550</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054861</td>\n",
       "      <td>-0.078808</td>\n",
       "      <td>-0.092320</td>\n",
       "      <td>-0.119765</td>\n",
       "      <td>-0.017133</td>\n",
       "      <td>-0.037570</td>\n",
       "      <td>-0.003405</td>\n",
       "      <td>-0.004435</td>\n",
       "      <td>-0.020573</td>\n",
       "      <td>-0.000585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rock</td>\n",
       "      <td>-0.001988</td>\n",
       "      <td>-0.003077</td>\n",
       "      <td>-0.002397</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099118</td>\n",
       "      <td>-0.116422</td>\n",
       "      <td>-0.045899</td>\n",
       "      <td>-0.041989</td>\n",
       "      <td>-0.078948</td>\n",
       "      <td>-0.059464</td>\n",
       "      <td>-0.132240</td>\n",
       "      <td>-0.115517</td>\n",
       "      <td>-0.035373</td>\n",
       "      <td>-0.039236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rock</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>-0.002852</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029565</td>\n",
       "      <td>0.116452</td>\n",
       "      <td>0.115272</td>\n",
       "      <td>0.312533</td>\n",
       "      <td>0.361796</td>\n",
       "      <td>0.340224</td>\n",
       "      <td>0.447560</td>\n",
       "      <td>0.505576</td>\n",
       "      <td>0.706916</td>\n",
       "      <td>0.620015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rock</td>\n",
       "      <td>-0.002345</td>\n",
       "      <td>-0.003766</td>\n",
       "      <td>-0.004752</td>\n",
       "      <td>-0.001465</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>-0.000928</td>\n",
       "      <td>-0.001434</td>\n",
       "      <td>-0.003766</td>\n",
       "      <td>-0.004756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062377</td>\n",
       "      <td>-0.057751</td>\n",
       "      <td>-0.148933</td>\n",
       "      <td>-0.111224</td>\n",
       "      <td>-0.028607</td>\n",
       "      <td>0.026423</td>\n",
       "      <td>0.008661</td>\n",
       "      <td>-0.071092</td>\n",
       "      <td>-0.058597</td>\n",
       "      <td>-0.021446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>-0.012173</td>\n",
       "      <td>0.015278</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>-0.005186</td>\n",
       "      <td>-0.015326</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>-0.012609</td>\n",
       "      <td>-0.090091</td>\n",
       "      <td>-0.095443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196053</td>\n",
       "      <td>0.266813</td>\n",
       "      <td>0.289611</td>\n",
       "      <td>0.187709</td>\n",
       "      <td>0.149948</td>\n",
       "      <td>0.166143</td>\n",
       "      <td>0.086306</td>\n",
       "      <td>0.032596</td>\n",
       "      <td>-0.081602</td>\n",
       "      <td>-0.092399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>-0.007904</td>\n",
       "      <td>-0.003071</td>\n",
       "      <td>-0.001817</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>0.007040</td>\n",
       "      <td>0.010066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236072</td>\n",
       "      <td>0.294226</td>\n",
       "      <td>0.274508</td>\n",
       "      <td>0.255579</td>\n",
       "      <td>0.187992</td>\n",
       "      <td>0.121793</td>\n",
       "      <td>0.154414</td>\n",
       "      <td>-0.051746</td>\n",
       "      <td>-0.008415</td>\n",
       "      <td>0.220748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>-0.001573</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>-0.004585</td>\n",
       "      <td>-0.004874</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078580</td>\n",
       "      <td>-0.023332</td>\n",
       "      <td>-0.046219</td>\n",
       "      <td>0.066519</td>\n",
       "      <td>-0.046962</td>\n",
       "      <td>-0.168407</td>\n",
       "      <td>-0.097263</td>\n",
       "      <td>-0.092109</td>\n",
       "      <td>-0.109068</td>\n",
       "      <td>-0.244396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.005652</td>\n",
       "      <td>0.005726</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254142</td>\n",
       "      <td>0.372470</td>\n",
       "      <td>0.226492</td>\n",
       "      <td>0.169134</td>\n",
       "      <td>0.197148</td>\n",
       "      <td>0.133427</td>\n",
       "      <td>0.028967</td>\n",
       "      <td>0.041120</td>\n",
       "      <td>-0.026155</td>\n",
       "      <td>0.016971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Electronic</td>\n",
       "      <td>-0.013152</td>\n",
       "      <td>0.013264</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>-0.002659</td>\n",
       "      <td>0.013009</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>-0.003092</td>\n",
       "      <td>-0.003445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302995</td>\n",
       "      <td>0.356019</td>\n",
       "      <td>0.262199</td>\n",
       "      <td>0.163441</td>\n",
       "      <td>0.416613</td>\n",
       "      <td>0.398118</td>\n",
       "      <td>0.223224</td>\n",
       "      <td>0.151641</td>\n",
       "      <td>-0.131778</td>\n",
       "      <td>-0.373704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 238001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label         0         1         2         3         4         5  \\\n",
       "0         Rock  0.002090  0.002457  0.003026 -0.003531  0.000593 -0.000422   \n",
       "1         Rock  0.000280  0.000392  0.000608 -0.000550  0.000869  0.000239   \n",
       "2         Rock -0.001988 -0.003077 -0.002397  0.000297  0.000106  0.001610   \n",
       "3         Rock -0.001400  0.002623  0.003775  0.000649  0.000363  0.004158   \n",
       "4         Rock -0.002345 -0.003766 -0.004752 -0.001465 -0.000347 -0.000928   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "85  Electronic -0.012173  0.015278  0.002091 -0.005186 -0.015326  0.007420   \n",
       "86  Electronic -0.007904 -0.003071 -0.001817  0.000821  0.004140  0.009747   \n",
       "87  Electronic  0.000441 -0.001573 -0.001202  0.000164 -0.004585 -0.004874   \n",
       "88  Electronic  0.000145  0.003849  0.001637  0.004717  0.005652  0.005726   \n",
       "89  Electronic -0.013152  0.013264  0.010753  0.000557 -0.002659  0.013009   \n",
       "\n",
       "           6         7         8  ...    237990    237991    237992    237993  \\\n",
       "0  -0.004120  0.000559 -0.003272  ...  0.248962  0.085129 -0.020552 -0.232211   \n",
       "1  -0.000428  0.000423 -0.000243  ... -0.054861 -0.078808 -0.092320 -0.119765   \n",
       "2   0.004233  0.002088  0.001651  ... -0.099118 -0.116422 -0.045899 -0.041989   \n",
       "3   0.001411 -0.002852  0.000627  ...  0.029565  0.116452  0.115272  0.312533   \n",
       "4  -0.001434 -0.003766 -0.004756  ...  0.062377 -0.057751 -0.148933 -0.111224   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "85 -0.012609 -0.090091 -0.095443  ...  0.196053  0.266813  0.289611  0.187709   \n",
       "86  0.005562  0.007040  0.010066  ...  0.236072  0.294226  0.274508  0.255579   \n",
       "87 -0.001185  0.000745  0.002968  ... -0.078580 -0.023332 -0.046219  0.066519   \n",
       "88  0.001288  0.002571  0.001654  ...  0.254142  0.372470  0.226492  0.169134   \n",
       "89  0.005518 -0.003092 -0.003445  ...  0.302995  0.356019  0.262199  0.163441   \n",
       "\n",
       "      237994    237995    237996    237997    237998    237999  \n",
       "0  -0.366932 -0.380118 -0.329189 -0.377189 -0.429503 -0.469498  \n",
       "1  -0.017133 -0.037570 -0.003405 -0.004435 -0.020573 -0.000585  \n",
       "2  -0.078948 -0.059464 -0.132240 -0.115517 -0.035373 -0.039236  \n",
       "3   0.361796  0.340224  0.447560  0.505576  0.706916  0.620015  \n",
       "4  -0.028607  0.026423  0.008661 -0.071092 -0.058597 -0.021446  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "85  0.149948  0.166143  0.086306  0.032596 -0.081602 -0.092399  \n",
       "86  0.187992  0.121793  0.154414 -0.051746 -0.008415  0.220748  \n",
       "87 -0.046962 -0.168407 -0.097263 -0.092109 -0.109068 -0.244396  \n",
       "88  0.197148  0.133427  0.028967  0.041120 -0.026155  0.016971  \n",
       "89  0.416613  0.398118  0.223224  0.151641 -0.131778 -0.373704  \n",
       "\n",
       "[90 rows x 238001 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "def train_valid_test_split( dataset , perc_train , set_seed = 69):\n",
    "\n",
    "    train = dataset.sample(frac= perc_train,random_state = set_seed )\n",
    "    test  = dataset.drop(train.index)\n",
    "\n",
    "    return (train , test )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset , test_dataset = train_valid_test_split( data , perc_train = .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Jazz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label\n",
       "31        Jazz\n",
       "25         Pop\n",
       "57     Hip-Hop\n",
       "80  Electronic\n",
       "52     Hip-Hop\n",
       "..         ...\n",
       "53     Hip-Hop\n",
       "88  Electronic\n",
       "37        Jazz\n",
       "12        Rock\n",
       "38        Jazz\n",
       "\n",
       "[81 rows x 1 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.iloc[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/paolo/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/paolo/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/paolo/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/paolo/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/paolo/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Importing required libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "X = train_dataset.iloc[: , 1:]\n",
    "y = train_dataset.iloc[: , :1]\n",
    "\n",
    "#Implementing cross validation\n",
    "\n",
    "k = 3\n",
    "kf = KFold( n_splits=k, random_state= None , shuffle= True )\n",
    "model = LogisticRegression()\n",
    "\n",
    "acc_score = []\n",
    "for j in range(k):\n",
    "    x_train , x_validation = train_valid_test_split( X , perc_train = .78 , set_seed= j)\n",
    "    y_train , y_validation = train_valid_test_split( y , perc_train = .78 , set_seed= j)\n",
    "    \n",
    "    model.fit(x_train , y_train)\n",
    "    pred_values = model.predict(x_validation)\n",
    "    \n",
    "    acc = accuracy_score( pred_values , y_validation)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "avg_acc_score = sum(acc_score)/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of each fold - [0.2222222222222222, 0.3333333333333333, 0.16666666666666666]\n",
      "Avg accuracy : 0.24074074074074073\n"
     ]
    }
   ],
   "source": [
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( stacked_single_tensors , labels, test_size=0.2, random_state=42 )\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticPredictions = logistic.predict( X_test )\n",
    "Logistic_Accuracy = logistic.score( X_test , Y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logistic_Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 4, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 0],\n",
       "       [0, 4, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 0],\n",
       "       [0, 4, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix( Y_test , LogisticPredictions , labels = None, sample_weight=None, normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "key_fold = KFold( n_splits=4 ) \n",
    "key_fold.get_n_splits(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(stacked_single_tensors)\n",
    "X = df.iloc[:,:-1]\n",
    "y = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from tqdm import tqdm\n",
    "set.seed(69)\n",
    "\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "\n",
    "#convert y values to categorical values\n",
    "\n",
    "y = pd.DataFrame(labels)\n",
    "\n",
    "#Implementing cross validation\n",
    "\n",
    "k = 3\n",
    "kf = KFold(n_splits=k, random_state= None , shuffle= True )\n",
    "model = LogisticRegression()\n",
    "\n",
    "acc_score = []\n",
    "\n",
    "for train_index , test_index in tqdm( kf.split(X) ):\n",
    "\n",
    "    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train , y_test = y.iloc[train_index] , y.iloc[test_index]\n",
    "\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score( pred_values , y_test)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "avg_acc_score = sum(acc_score)/k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of each fold - [0.14814814814814814, 0.1111111111111111, 0.25925925925925924]\n",
      "Avg accuracy : 0.1728395061728395\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4667d31aad76a2fc6367a343b03ad539ee0fdcfaae0637945dddaa0789b3d6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
